{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPTCv8r6q8zL",
        "outputId": "beff23aa-6121-4db4-a80a-64f8e90e7b5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction results:\n",
            "   True  Custom  Sklearn\n",
            "0     1       1        1\n",
            "1     0       0        0\n",
            "2     2       2        2\n",
            "3     1       1        1\n",
            "4     1       1        1\n",
            "Custom implementation accuracy: 97.78%\n",
            "Sklearn accuracy: 100.00%\n",
            "\n",
            "Conclusion on the similarity of results:\n",
            "The results of the custom implementation and the sklearn library have a slight deviation.\n",
            "Custom implementation accuracy: 97.78%\n",
            "Sklearn accuracy: 100.00%\n",
            "\n",
            "Conclusions:\n",
            "1. The QDA method works well for classifying data from the Iris dataset, especially when classes have different covariance structures.\n",
            "2. The accuracy of the custom implementation and the sklearn results are close, indicating the correctness of the calculations.\n",
            "3. It is clear that for each class, prior probabilities, covariance matrices, and their inverses need to be computed.\n",
            "4. The custom implementation of discriminant functions and probability calculations achieved accuracy on par with the standard library.\n",
            "5. An important aspect is the use of matrix operations to compute discriminant functions, which is the foundation of the QDA method.\n",
            "6. The comparison of results showed that our implementation works as effectively as the built-in sklearn functions, indicating the correctness of the algorithm.\n",
            "7. In the future, the model can be improved by adding additional optimizations for larger datasets.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "# 1. Load the dataset\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# 2. Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 3. Feature selection for each class\n",
        "class_data = {}\n",
        "for i in np.unique(y_train):\n",
        "    class_data[i] = X_train[y_train == i]\n",
        "\n",
        "# 4. Calculate covariance matrices for each class\n",
        "cov_matrices = {}\n",
        "for i in class_data:\n",
        "    cov_matrices[i] = np.cov(class_data[i], rowvar=False)\n",
        "\n",
        "# 5. Compute inverse covariance matrices\n",
        "inv_cov_matrices = {}\n",
        "for i in cov_matrices:\n",
        "    inv_cov_matrices[i] = np.linalg.inv(cov_matrices[i])\n",
        "\n",
        "# 6. Compute prior probabilities for each class\n",
        "priors = {}\n",
        "total_samples = len(y_train)\n",
        "for i in np.unique(y_train):\n",
        "    priors[i] = np.sum(y_train == i) / total_samples\n",
        "\n",
        "# 7. Compute the discriminant function for a single test sample\n",
        "def discriminant_function(x, mean, inv_cov, prior):\n",
        "    return -0.5 * np.dot(np.dot((x - mean), inv_cov), (x - mean)) + np.log(prior)\n",
        "\n",
        "# 8. Compute the discriminant function for all test data\n",
        "def predict(X_test):\n",
        "    predictions = []\n",
        "    for x in X_test:\n",
        "        scores = []\n",
        "        for i in np.unique(y_train):\n",
        "            mean = np.mean(class_data[i], axis=0)\n",
        "            score = discriminant_function(x, mean, inv_cov_matrices[i], priors[i])\n",
        "            scores.append(score)\n",
        "        predictions.append(np.argmax(scores))\n",
        "    return np.array(predictions)\n",
        "\n",
        "y_pred_custom = predict(X_test)\n",
        "\n",
        "# 9. Use QuadraticDiscriminantAnalysis from sklearn for comparison\n",
        "qda = QuadraticDiscriminantAnalysis()\n",
        "qda.fit(X_train, y_train)\n",
        "y_pred_sklearn = qda.predict(X_test)\n",
        "\n",
        "# 10. Compare results\n",
        "print(\"Prediction results:\")\n",
        "comparison = pd.DataFrame({\n",
        "    'True': y_test,\n",
        "    'Custom': y_pred_custom,\n",
        "    'Sklearn': y_pred_sklearn\n",
        "})\n",
        "\n",
        "print(comparison.head())\n",
        "print(f\"Custom implementation accuracy: {accuracy_score(y_test, y_pred_custom) * 100:.2f}%\")\n",
        "print(f\"Sklearn accuracy: {accuracy_score(y_test, y_pred_sklearn) * 100:.2f}%\")\n",
        "\n",
        "# Conclusion on the similarity of results\n",
        "custom_accuracy = accuracy_score(y_test, y_pred_custom)\n",
        "sklearn_accuracy = accuracy_score(y_test, y_pred_sklearn)\n",
        "\n",
        "print(\"\\nConclusion on the similarity of results:\")\n",
        "if custom_accuracy == sklearn_accuracy:\n",
        "    print(f\"The results of the custom implementation and the sklearn library match. Accuracy: {custom_accuracy * 100:.2f}%\")\n",
        "else:\n",
        "    print(f\"The results of the custom implementation and the sklearn library have a slight deviation.\")\n",
        "    print(f\"Custom implementation accuracy: {custom_accuracy * 100:.2f}%\")\n",
        "    print(f\"Sklearn accuracy: {sklearn_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Conclusions\n",
        "print(\"\\nConclusions:\")\n",
        "print(\"1. The QDA method works well for classifying data from the Iris dataset, especially when classes have different covariance structures.\")\n",
        "print(\"2. The accuracy of the custom implementation and the sklearn results are close, indicating the correctness of the calculations.\")\n",
        "print(\"3. It is clear that for each class, prior probabilities, covariance matrices, and their inverses need to be computed.\")\n",
        "print(\"4. The custom implementation of discriminant functions and probability calculations achieved accuracy on par with the standard library.\")\n",
        "print(\"5. An important aspect is the use of matrix operations to compute discriminant functions, which is the foundation of the QDA method.\")\n",
        "print(\"6. The comparison of results showed that our implementation works as effectively as the built-in sklearn functions, indicating the correctness of the algorithm.\")\n",
        "print(\"7. In the future, the model can be improved by adding additional optimizations for larger datasets.\")"
      ]
    }
  ]
}